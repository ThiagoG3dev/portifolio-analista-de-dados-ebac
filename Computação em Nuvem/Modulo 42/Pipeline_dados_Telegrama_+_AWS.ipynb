{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6f9bc9e4",
      "metadata": {
        "papermill": {
          "duration": 0.019526,
          "end_time": "2024-02-20T18:50:07.416786",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.397260",
          "status": "completed"
        },
        "tags": [],
        "id": "6f9bc9e4"
      },
      "source": [
        "# 1. Introdução"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c71d6ffe",
      "metadata": {
        "papermill": {
          "duration": 0.017131,
          "end_time": "2024-02-20T18:50:07.451491",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.434360",
          "status": "completed"
        },
        "tags": [],
        "id": "c71d6ffe"
      },
      "source": [
        "O presente projeto foi desenvolvido como conclusão do curso **Profissão Analista de Dados** da EBAC e tem como objetivo a construção de um **pipeline de dados em nuvem**.\n",
        "\n",
        "O pipeline de dados foi desenvolvido para ingerir, processar e armazenar mensagens de texto disparadas em um grupo do Telegram, criado exclusivamente para este trabalho.\n",
        "\n",
        "Junto ao grupo foi adicionado um bot, criado dentro da própria plataforma por meio do *botfather*, responsável por captar as mensagens e encaminha-lás via API para a plataforma cloud Amazon Web Services (AWS), onde as mensagens foram processadas, armazenadas, limpas e analisadas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f459fa7",
      "metadata": {
        "papermill": {
          "duration": 0.017358,
          "end_time": "2024-02-20T18:50:07.486440",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.469082",
          "status": "completed"
        },
        "tags": [],
        "id": "7f459fa7"
      },
      "source": [
        "# 2. Contexto"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b31373cc",
      "metadata": {
        "papermill": {
          "duration": 0.017022,
          "end_time": "2024-02-20T18:50:07.521037",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.504015",
          "status": "completed"
        },
        "tags": [],
        "id": "b31373cc"
      },
      "source": [
        "## 2.1 Chatbots"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45ec61c7",
      "metadata": {
        "papermill": {
          "duration": 0.017112,
          "end_time": "2024-02-20T18:50:07.555683",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.538571",
          "status": "completed"
        },
        "tags": [],
        "id": "45ec61c7"
      },
      "source": [
        "Um **chatbot** é um tipo de software que interage com usuários através de conversas automatizadas em plataformas de mensagens. Uma aplicação comum de chatbots é o seu uso no atendimento ao cliente, onde, de maneira geral, ajudam clientes a resolver problemas ou esclarecer dúvidas recorrentes antes mesmo que um atendente humano seja acionado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f62c81c",
      "metadata": {
        "papermill": {
          "duration": 0.017106,
          "end_time": "2024-02-20T18:50:07.590238",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.573132",
          "status": "completed"
        },
        "tags": [],
        "id": "9f62c81c"
      },
      "source": [
        "## 2.2 Telegram"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dad9b591",
      "metadata": {
        "papermill": {
          "duration": 0.016965,
          "end_time": "2024-02-20T18:50:07.624668",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.607703",
          "status": "completed"
        },
        "tags": [],
        "id": "dad9b591"
      },
      "source": [
        "Telegram é uma plataforma de mensagens instantâneas freeware (distribuído gratuitamente) e, em sua maioria, open source. É muito popular entre desenvolvedores por ser pioneiro na implantação da funcionalidade de criação de chatbots, que, por sua vez, permitem a criação de diversas automações."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96377e44",
      "metadata": {
        "papermill": {
          "duration": 0.017099,
          "end_time": "2024-02-20T18:50:07.659671",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.642572",
          "status": "completed"
        },
        "tags": [],
        "id": "96377e44"
      },
      "source": [
        "## 2.3 Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7af7c3ad",
      "metadata": {
        "papermill": {
          "duration": 0.017021,
          "end_time": "2024-02-20T18:50:07.694265",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.677244",
          "status": "completed"
        },
        "tags": [],
        "id": "7af7c3ad"
      },
      "source": [
        "Os dados presentes neste projeto podem ser divididos em dois tipos: **transacionais** e **analíticos**. Os dados transacionais são representados pelas mensagens enviadas por usuários em um grupo no Telegram, e os dados analíticos são os dados provenientes dos sistemas transacionais manipulados na etapa de ETL (extraction, transformation and load) e serão armazenados em uma camada **raw** e **enriched**, respectivamente."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "054f66ab",
      "metadata": {
        "papermill": {
          "duration": 0.01731,
          "end_time": "2024-02-20T18:50:07.729126",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.711816",
          "status": "completed"
        },
        "tags": [],
        "id": "054f66ab"
      },
      "source": [
        "# 3. Arquitetura"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99ca7865",
      "metadata": {
        "papermill": {
          "duration": 0.017153,
          "end_time": "2024-02-20T18:50:07.763529",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.746376",
          "status": "completed"
        },
        "tags": [],
        "id": "99ca7865"
      },
      "source": [
        "Este projeto tem como objetivo a construção de um **pipeline de dados** que processe, armazene e exponha as mensagens e suas informações referentes de um grupo do Telegram, para que profissionais da área de Dados possam realizar as análises pertinentes.\n",
        "\n",
        "Uma atividade de grande interesse para empresas que já utilizam ou pensam em utilizar os chatbots, é a **análise exploratória** dos dados enviados ao bot, para responder perguntas como:\n",
        "\n",
        "* Qual horário os usuários mais acionam o bot?\n",
        "* Qual dúvida ou problema mais recorrente?\n",
        "* O bot está conseguindo esclarecer as dúvidas?\n",
        "\n",
        "Para responder a essas perguntas, é necessário o desenvolvimento de uma arquitetura em duas partes: a transacional, representada pelos dados captados no grupo do Telegram e a analítica, realizada na plataforma Amazon Web Services (AWS) onde os dados são processados e analisados.\n",
        "\n",
        "A sintese da arquitetura é representada pela imagem abaixo:\n",
        "\n",
        "![image.png](attachment:a2a276c9-5858-416f-8f88-093ac3f71ec7.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49774ffd",
      "metadata": {
        "papermill": {
          "duration": 0.017019,
          "end_time": "2024-02-20T18:50:07.797894",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.780875",
          "status": "completed"
        },
        "tags": [],
        "id": "49774ffd"
      },
      "source": [
        "## 3.1 Sistema Transacional"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "339da6be",
      "metadata": {
        "papermill": {
          "duration": 0.016943,
          "end_time": "2024-02-20T18:50:07.832239",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.815296",
          "status": "completed"
        },
        "tags": [],
        "id": "339da6be"
      },
      "source": [
        "O **Telegram** representa a fonte de dados transacionais deste projeto. Foi criado um grupo de usuários com a presença de um bot, responsável por capturar as mensagens e redirecioná-las via **webhook do backend** do aplicativo para um endpoint, exposto pela **API Gateway** (AWS Services).\n",
        "\n",
        "As mensagens trafegam no corpo ou payload da requisição."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b477eba9",
      "metadata": {
        "papermill": {
          "duration": 0.016918,
          "end_time": "2024-02-20T18:50:07.866622",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.849704",
          "status": "completed"
        },
        "tags": [],
        "id": "b477eba9"
      },
      "source": [
        "## 3.2 Sistema Analítico"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fb50cf7",
      "metadata": {
        "papermill": {
          "duration": 0.016764,
          "end_time": "2024-02-20T18:50:07.901010",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.884246",
          "status": "completed"
        },
        "tags": [],
        "id": "9fb50cf7"
      },
      "source": [
        "A etapa analítica do projeto consiste na ingestão, **ETL** (extract, transform, load) e apresentação dos dados. Ela foi realizada no Amazon Web Services (AWS) através dos serviços **API Gateway, Lambda, S3, EventBridge e Athena**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "598ccce6",
      "metadata": {
        "papermill": {
          "duration": 0.016599,
          "end_time": "2024-02-20T18:50:07.935089",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.918490",
          "status": "completed"
        },
        "tags": [],
        "id": "598ccce6"
      },
      "source": [
        "![image.png](attachment:f0ab426c-b88d-4f13-849d-2e8e0be1ace6.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80e7bb50",
      "metadata": {
        "papermill": {
          "duration": 0.01708,
          "end_time": "2024-02-20T18:50:07.969913",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.952833",
          "status": "completed"
        },
        "tags": [],
        "id": "80e7bb50"
      },
      "source": [
        "### 3.2.1 Ingestão"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca981426",
      "metadata": {
        "papermill": {
          "duration": 0.017027,
          "end_time": "2024-02-20T18:50:08.004272",
          "exception": false,
          "start_time": "2024-02-20T18:50:07.987245",
          "status": "completed"
        },
        "tags": [],
        "id": "ca981426"
      },
      "source": [
        "A etapa de **ingestão** é responsável por inserir os dados transacionais no ambiente analítico. Como o Telegram retem as mensagens por apenas 24 horas, a ingestão via **streaming** é a mais indicada para este projeto.\n",
        "\n",
        "Uma requisição **HTTP** com o conteúdo da mensagem em seu payload é recebida pelo **AWS API Gateway** que, por sua vez, as redireciona para o **AWS Lambda**, servindo assim como gatilho. Já o **AWS Lambda** recebe o *payload* da requisição em seu parâmetro *event*, que salva o conteúdo em um arquivo de formato **JSON** (original) e o armazena em um bucket específico no **AWS S3** particionado por dia.\n",
        "\n",
        "As mensagens capturadas pelo bot podem ser acessadas via **API**. A única requisição necessária é o `token` fornecido pelo **botFather** na criação do bot. Por isso, começamos com a autenticação abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbbb9c2d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-20T18:50:08.041441Z",
          "iopub.status.busy": "2024-02-20T18:50:08.040721Z",
          "iopub.status.idle": "2024-02-20T18:50:08.641371Z",
          "shell.execute_reply": "2024-02-20T18:50:08.639838Z"
        },
        "papermill": {
          "duration": 0.621615,
          "end_time": "2024-02-20T18:50:08.643404",
          "exception": true,
          "start_time": "2024-02-20T18:50:08.021789",
          "status": "failed"
        },
        "tags": [],
        "id": "bbbb9c2d",
        "outputId": "edad2f68-eb49-4814-ccb8-9a6916aab858"
      },
      "outputs": [
        {
          "ename": "StdinNotImplementedError",
          "evalue": "getpass was called, but this frontend does not support input requests.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStdinNotImplementedError\u001b[0m                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#autenticando o token\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgetpass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getpass\n\u001b[0;32m----> 5\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[43mgetpass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1165\u001b[0m, in \u001b[0;36mKernel.getpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1164\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetpass was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
            "\u001b[0;31mStdinNotImplementedError\u001b[0m: getpass was called, but this frontend does not support input requests."
          ]
        }
      ],
      "source": [
        "#autenticando o token\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "token = getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9c6ec9",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "9d9c6ec9"
      },
      "outputs": [],
      "source": [
        "#pacotes e bibliotecas\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "import logging\n",
        "from datetime import datetime, timedelta, timezone\n",
        "\n",
        "import boto3\n",
        "\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef12da7",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "aef12da7"
      },
      "outputs": [],
      "source": [
        "# A url base é comum a todos os métodos da API\n",
        "\n",
        "base_url = f'https://api.telegram.org/bot{token}'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f81cf16e",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "f81cf16e"
      },
      "source": [
        "O código abaixo representa a **função do Lambda** que recebe as mensagens do **Telegram** via **API Gateway**, verifica no seu conteúdo se elas foram produzidas no grupo especificado e as escreve em seu formato original **JSON**, em um bucket no **AWS S3**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4d8885e",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "a4d8885e"
      },
      "outputs": [],
      "source": [
        "def lambda_handler(event: dict, context: dict) -> dict:\n",
        "\n",
        "  #variáveis de ambiente\n",
        "\n",
        "  BUCKET = os.environ['AWS_S3_BUCKET']\n",
        "  TELEGRAM_CHAT_ID = int(os.environ['TELEGRAM_CHAT_ID'])\n",
        "\n",
        "  #variáveis lógicas\n",
        "\n",
        "  tzinfo = timezone(offset=timedelta(hours=-3))\n",
        "  date = datetime.now(tzinfo).strftime('%Y-%m-%d')\n",
        "  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "  filename = f'{timestamp}.json'\n",
        "\n",
        "  #código\n",
        "\n",
        "  client = boto3.client('s3')\n",
        "\n",
        "  try:\n",
        "\n",
        "    message = json.loads(event[\"body\"])\n",
        "    chat_id = message[\"message\"][\"chat\"][\"id\"]\n",
        "\n",
        "    if chat_id == TELEGRAM_CHAT_ID:\n",
        "\n",
        "      with open(f\"/tmp/{filename}\", mode='w', encoding='utf8') as fp:\n",
        "        json.dump(message, fp)\n",
        "\n",
        "      client.upload_file(f'/tmp/{filename}', BUCKET, f'telegram/context_date={date}/{filename}')\n",
        "\n",
        "  except Exception as exc:\n",
        "      logging.error(msg=exc)\n",
        "      return dict(statusCode=\"500\")\n",
        "\n",
        "  else:\n",
        "      return dict(statusCode=\"200\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef4e9a68",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "ef4e9a68"
      },
      "source": [
        "Para testar a integração do **AWS Lambda** com a **API**, devemos fazer a implantação da **API** e obter seu endereço web. Com a url gerada, incluímos ela na variável `aws_api_gateway_url`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a38021ae",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "a38021ae"
      },
      "source": [
        "aws_api_gateway_url = getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8137351c",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "8137351c"
      },
      "source": [
        "O método `setWebhook` configura o redirecionamento das mensagens captadas pelo bot para o endereço web do parâmetro url, e o método `getWebhookInfo` retorna as informações sobre o webhook configurado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75a74f91",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "75a74f91"
      },
      "outputs": [],
      "source": [
        "#setWebhook\n",
        "\n",
        "response = requests.get(url=f'{base_url}/setWebhook?url={aws_api_gateway_url}')\n",
        "\n",
        "print(json.dumps(json.loads(response.text), indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de49f200",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "de49f200"
      },
      "outputs": [],
      "source": [
        "#getWebhookInfo\n",
        "\n",
        "response = requests.get(url=f'{base_url}/getWebhookInfo')\n",
        "\n",
        "print(json.dumps(json.loads(response.text), indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "739ffbbb",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "739ffbbb"
      },
      "source": [
        "### 3.2.2 ETL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ed4d557",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "3ed4d557"
      },
      "source": [
        "A etapa de **extração, transformação e carregamento** é a etapa responsável pela manipulação dos dados extraídos na etapa transacional, ou seja, persistidos em camadas cruas (*raw*) dos sistemas analíticos. O dado cru armazenado passa por um processo recorrente onde ele é limpo, duplicado e persistido com técnicas de particionamento, orientado a coluna e compressão. Ao final, o dado está pronto para ser analisado por profissionais da área.\n",
        "\n",
        "Uma vez ao dia, o **AWS Event Brigde** aciona o **AWS Lambda** que, por sua vez, processa todas as mensagens geradas no dia anterior (D-1), desnormaliza o dado semi-estruturado típico de arquivos **JSON**, salva o conteúdo processado em um arquivo no formato Apache Parquet e o armazena no **AWS S3** particionado por dia.\n",
        "\n",
        "O código abaixo é **executado diariamente pelo AWS Lambda** - acionado pelo AWS Event Bridge - para compactar as diversas mensagens que chegam no grupo (do dia anterior), no formato JSON armazenadas no bucket de dados cru (raw), em um único arquivo no formato Parquet. Após o processamento, as mensagens são armazenadas no bucket de dados enriquecidos (enriched)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfd7b6d5",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "bfd7b6d5"
      },
      "outputs": [],
      "source": [
        "def lambda_handler(event: dict, context: dict) -> bool:\n",
        "\n",
        "  #variáveis de ambiente\n",
        "\n",
        "  RAW_BUCKET = os.environ['AWS_S3_BUCKET']\n",
        "  ENRICHED_BUCKET = os.environ['AWS_S3_ENRICHED']\n",
        "\n",
        "  #variáveis lógicas\n",
        "\n",
        "  tzinfo = timezone(offset=timedelta(hours=-3))\n",
        "  date = (datetime.now(tzinfo) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "  #código\n",
        "\n",
        "  table = None\n",
        "  client = boto3.client('s3')\n",
        "\n",
        "  try:\n",
        "\n",
        "      response = client.list_objects_v2(Bucket=RAW_BUCKET, Prefix=f'telegram/context_date={date}')\n",
        "\n",
        "      for content in response['Contents']:\n",
        "\n",
        "        key = content['Key']\n",
        "        client.download_file(RAW_BUCKET, key, f\"/tmp/{key.split('/')[-1]}\")\n",
        "\n",
        "        with open(f\"/tmp/{key.split('/')[-1]}\", mode='r', encoding='utf8') as fp:\n",
        "\n",
        "          data = json.load(fp)\n",
        "          data = data[\"message\"]\n",
        "\n",
        "        parsed_data = parse_data(data=data)\n",
        "        iter_table = pa.Table.from_pydict(mapping=parsed_data)\n",
        "\n",
        "        if table:\n",
        "\n",
        "          table = pa.concat_tables([table, iter_table])\n",
        "\n",
        "        else:\n",
        "\n",
        "          table = iter_table\n",
        "          iter_table = None\n",
        "\n",
        "      pq.write_table(table=table, where=f'/tmp/{timestamp}.parquet')\n",
        "      client.upload_file(f\"/tmp/{timestamp}.parquet\", ENRICHED_BUCKET, f\"telegram/context_date={date}/{timestamp}.parquet\")\n",
        "\n",
        "      return True\n",
        "\n",
        "  except Exception as exc:\n",
        "      logging.error(msg=exc)\n",
        "      return False\n",
        "\n",
        "def parse_data(data: dict) -> dict:\n",
        "\n",
        "  date = datetime.now().strftime('%Y-%m-%d')\n",
        "  timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "  parsed_data = dict()\n",
        "\n",
        "  for key, value in data.items():\n",
        "\n",
        "      if key == 'from':\n",
        "          for k, v in data[key].items():\n",
        "              if k in ['id', 'is_bot', 'first_name']:\n",
        "                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
        "\n",
        "      elif key == 'chat':\n",
        "          for k, v in data[key].items():\n",
        "              if k in ['id', 'type']:\n",
        "                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
        "\n",
        "      elif key in ['message_id', 'date', 'text']:\n",
        "          parsed_data[key] = [value]\n",
        "\n",
        "  if not 'text' in parsed_data.keys():\n",
        "    parsed_data['text'] = [None]\n",
        "\n",
        "  return parsed_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e87bb19c",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "e87bb19c"
      },
      "source": [
        "Note que código acima possui uma função chamada `parse_data`, que executa um laço de repetição para varrer todas as chaves do arquivo e selecionar apenas a text, que é a única de interesse deste projeto. Caso a mensagem não possua a chave text, ela será criada com o valor `None`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d5083a2",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "0d5083a2"
      },
      "source": [
        "### 3.2.3 Apresentação dos Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88fb6126",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "88fb6126"
      },
      "source": [
        "Nesta etapa, o **AWS Athena** tem como função **apresentar os dados aos usuários e sistemas**, através de uma interface **SQL**. Portanto, é necessário a criação de uma tabela externa sobre o dado armazenado na camada mais refinada da arquitetura, a camada enriquecida (enriched) - entregando assim dados mais consistentes e com consultas mais baratas.\n",
        "\n",
        "Para criar a tabela, executamos as seguintes *queries*:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e44e69f3",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "e44e69f3"
      },
      "source": [
        "```sql\n",
        "CREATE EXTERNAL TABLE `telegram`(\n",
        "  `message_id` bigint,\n",
        "  `user_id` bigint,\n",
        "  `user_is_bot` boolean,\n",
        "  `user_first_name` string,\n",
        "  `chat_id` bigint,\n",
        "  `chat_type` string,\n",
        "  `text` string,\n",
        "  `date` bigint)\n",
        "PARTITIONED BY (\n",
        "  `context_date` date)\n",
        "ROW FORMAT SERDE\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
        "STORED AS INPUTFORMAT\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'\n",
        "OUTPUTFORMAT\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'\n",
        "LOCATION\n",
        "  's3://<bucket-enriquecido>/'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbdbc33a",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "dbdbc33a"
      },
      "source": [
        "Para adicionar as partições em uma única tabela:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7309e435",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "7309e435"
      },
      "source": [
        "```sql\n",
        "MSCK REPAIR TABLE `telegram`;\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c432815",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "1c432815"
      },
      "source": [
        "E para confirmar que os dados foram carregados, vamos executar uma query para exibir 10 valores:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "239a163f",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "239a163f"
      },
      "source": [
        "```sql\n",
        "SELECT * FROM `telegram` LIMIT 10;\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6207975",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "b6207975"
      },
      "source": [
        "![image.png](attachment:01eb2cbf-ffc7-47e5-aa79-e8390d2629f1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8a7bde3",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "a8a7bde3"
      },
      "source": [
        "# 4. Análise Exploratória de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a94b50ef",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "a94b50ef"
      },
      "source": [
        "Agora, com as funções criadas e agendadas e com as tabelas alimentadas, podemos executar algumas análises exploratórias, como exemplo:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f075fb",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "75f075fb"
      },
      "source": [
        "**Quantidade de mensagens por dia:**\n",
        "\n",
        "```sql\n",
        "SELECT\n",
        "  context_date,\n",
        "  count(1) AS \"message_amount\"\n",
        "FROM \"telegram\"\n",
        "GROUP BY context_date\n",
        "ORDER BY context_date DESC\n",
        "```\n",
        "\n",
        "![image.png](attachment:993fbe2b-8fa4-451a-9728-2014cfa7fcb4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a23a832d",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "a23a832d"
      },
      "source": [
        "**Quantidade de mensagens por usuários por dia**\n",
        "\n",
        "```sql\n",
        "SELECT\n",
        "  user_id,\n",
        "  user_first_name,\n",
        "  context_date,\n",
        "  count(1) AS \"message_amount\"\n",
        "FROM \"telegram\"\n",
        "GROUP BY\n",
        "  user_id,\n",
        "  user_first_name,\n",
        "  context_date\n",
        "ORDER BY context_date DESC\n",
        "```\n",
        "\n",
        "![image.png](attachment:6095f439-134b-4bee-958d-e9faba483f71.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "246a3e21",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "246a3e21"
      },
      "source": [
        "**Média do tamanho das mensagens de cada usuário por dia**\n",
        "\n",
        "```sql\n",
        "SELECT\n",
        "  user_id,\n",
        "  user_first_name,\n",
        "  context_date,\n",
        "  CAST(AVG(length(text)) AS INT) AS \"average_message_length\"\n",
        "FROM \"telegram\"\n",
        "GROUP BY\n",
        "  user_id,\n",
        "  user_first_name,\n",
        "  context_date\n",
        "ORDER BY context_date DESC\n",
        "```\n",
        "\n",
        "![image.png](attachment:2d10fb2b-5408-41d9-8247-5646a22c46b0.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8921071",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "e8921071"
      },
      "source": [
        "**Quantidade de mensagens por hora por dia da semana por número da semana**\n",
        "\n",
        "```sql\n",
        "WITH\n",
        "parsed_date_cte AS (\n",
        "    SELECT\n",
        "        *,\n",
        "        CAST(date_format(from_unixtime(\"date\"),'%Y-%m-%d %H:%i:%s') AS timestamp) AS parsed_date\n",
        "    FROM \"telegram\"\n",
        "),\n",
        "hour_week_cte AS (\n",
        "    SELECT\n",
        "        *,\n",
        "        EXTRACT(hour FROM parsed_date) AS parsed_date_hour,\n",
        "        EXTRACT(dow FROM parsed_date) AS parsed_date_weekday,\n",
        "        EXTRACT(week FROM parsed_date) AS parsed_date_weeknum\n",
        "    FROM parsed_date_cte\n",
        ")\n",
        "SELECT\n",
        "    parsed_date_hour,\n",
        "    parsed_date_weekday,\n",
        "    parsed_date_weeknum,\n",
        "    count(1) AS \"message_amount\"\n",
        "FROM hour_week_cte\n",
        "GROUP BY\n",
        "    parsed_date_hour,\n",
        "    parsed_date_weekday,\n",
        "    parsed_date_weeknum\n",
        "ORDER BY\n",
        "    parsed_date_weeknum,\n",
        "    parsed_date_weekday\n",
        "```\n",
        "\n",
        "![image.png](attachment:8aa84cf9-8426-4b0f-8dc6-d1ec99097e08.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe5b3a36",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "fe5b3a36"
      },
      "source": [
        "# 5. Conclusão\n",
        "\n",
        "A utilização de *chatbots* juntamente com a **análise dos dados extraídos através de um pipeline**, são de grande utilidade para empresas de todo porte, como demonstrado acima. Os *chatbots* facilitam a interação dos clientes com a empresa, uma vez que podem resolver problemas e tirar dúvidas pelo seu smarphone/web sem precisar ir até uma loja ou entrar em contato diretamente com algum funcionário. Os dados extraídos dessas interações fornecem *insights* de grande valor para os tomadores de decisão, uma vez que as análises personalizadas de acordo com suas demandas, fornecem informações que vão desde o comportamento dos seus clientes, até esclarecimentos e feedbacks sobre os produtos oferecidos.\n",
        "\n",
        "Este projeto **permitiu conhecer os serviços oferecidos pela Amazon Web Services** e entender todo o potencial que os mesmos possuem para o analista de dados.\n",
        "\n",
        "Também foi possível perceber como o formato **parquet** melhorou o desempenho das consultas.\n",
        "\n",
        "Foi extremamente fácil fazer a **API do Telegram** funcionar com os serviços da AWS. Uma vez criada a API ela funcionou corretamente e se manteve em funcionamento sem problemas.\n",
        "\n",
        "Ficará para um próximo projeto, testar a comunicação entre o AWS Athena e o **Microsoft Power BI**."
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30497,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 15.365878,
      "end_time": "2024-02-20T18:50:09.583311",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-02-20T18:49:54.217433",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}